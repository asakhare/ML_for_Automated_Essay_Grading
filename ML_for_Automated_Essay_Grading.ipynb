{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning model for grading essays written in English.\n",
    "\n",
    "By,\n",
    "\n",
    "Anand Sakhare\n",
    "\n",
    "MISM-BIDA Graduate Student | Carnegie Mellon University\n",
    "\n",
    "Mobile: (412)708-7836\n",
    "\n",
    "Email: asakhare@andrew.cmu.edu\n",
    "\n",
    "LinkedIn: https://www.linkedin.com/in/anand-sakhare/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The input data is a cleaned up version of  dataset from a kaggle competition.\n",
    "Competition Name - The Hewlett Foundation: Automated Essay Scoring\n",
    "Source: https://www.kaggle.com/c/asap-aes\n",
    "\n",
    "Brief description of the steps that I followed for building the model:\n",
    "\n",
    "1. Read all the data from CSV\n",
    "2. Make the text essays lowercase\n",
    "3. Removing the stop words\n",
    "4. Lemmatizing all the words in the essays so that variation is reduced\n",
    "5. Removing punctuation from the essays\n",
    "6. Compute geometrical features such as length and number of digits\n",
    "7. For each essay count the number of words belonging to each type of part of speech\n",
    "8. Compute a tfidf sparse matrix and reduce it's dimensionality\n",
    "9. Join all the features (tfidf sparse matrix, part of speech features and goemetrical features)\n",
    "10. Split the data into trianing and testing data\n",
    "11. Create a grid for hyper parameter tuning of the random forest classifier\n",
    "12. Perform hyperparameter tuning and come up with the best estimator and parameters for the random forest classifier\n",
    "13. Predict the output on the test data and evaluate the model\n",
    "\n",
    "##### Please make sure following libraries are downloaded/installed on your system before running this file.\n",
    "Pandas, Numpy, nltk, stop_words, re, collections, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     y\n",
       "0  Dear local newspaper, I think effects computer...   8.0\n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...   9.0\n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   7.0\n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...  10.0\n",
       "4  Dear @LOCATION1, I know having computers has a...   8.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import all the data\n",
    "import pandas as pd\n",
    "data = pd.read_csv('train_set_rel3.csv',encoding='latin-1')\n",
    "data = data.dropna(axis=0, how='any')      #Drop NA values\n",
    "df = data\n",
    "df = data[['essay','domain1_score']]\n",
    "df.columns = ['text','y'] #Take essays and the scores\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     y\n",
      "0  dear local newspaper, i think effects computer...   8.0\n",
      "1  dear @caps1 @caps2, i believe that using compu...   9.0\n",
      "2  dear, @caps1 @caps2 @caps3 more and more peopl...   7.0\n",
      "3  dear local newspaper, @caps1 i have found that...  10.0\n",
      "4  dear @location1, i know having computers has a...   8.0\n",
      "Wall time: 77.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Make all the text essays lowercase\n",
    "df['text'] = df['text'].str.lower()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Remove the stopwords : stopwords are taken from two libraries - 'stop_words' and 'nltk'\n",
    "essay_list = df['text']\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_list = set(get_stop_words('en')).union(set(stopwords.words('english')))  #Combining the stop words from both the packages\n",
    "\n",
    "processed_essays = []\n",
    "essay_list = list(essay_list)\n",
    "for i in essay_list:\n",
    "    temp = i\n",
    "    parsed_essay = \" \".join([word for word in temp.split() if word not in stop_words_list])\n",
    "    processed_essays.append(parsed_essay)\n",
    "#df['text'] = processed_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Wall time: 7.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Lemmatize all the words in the essays\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "#Source: https://stackoverflow.com/questions/771918/how-do-i-do-word-stemming-or-lemmatization\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "s = \"\"\n",
    "for i in range(len(processed_essays)):\n",
    "    s = \"\"\n",
    "    for word in processed_essays[i].split():\n",
    "        s = s + lmtzr.lemmatize(word) + \" \"\n",
    "    processed_essays[i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 268 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Remove Punctuation\n",
    "#Reference: https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\n",
    "import re\n",
    "for i in range(len(processed_essays)):\n",
    "    processed_essays[i] = re.sub(r'[^\\w\\s]','',processed_essays[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Append to the dataframe df\n",
    "df['text'] = processed_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear caps1 caps2 believe using computer benefi...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dear caps1 caps2 caps3 people use computers ev...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear local newspaper caps1 found many expert s...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear location1 know computer positive effect p...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     y  length\n",
       "0  dear local newspaper think effect computer peo...   8.0    1110\n",
       "1  dear caps1 caps2 believe using computer benefi...   9.0    1460\n",
       "2  dear caps1 caps2 caps3 people use computers ev...   7.0     952\n",
       "3  dear local newspaper caps1 found many expert s...  10.0    2110\n",
       "4  dear location1 know computer positive effect p...   8.0    1466"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the length of each essay - this will serve as a geometrical parameter\n",
    "len_values = []\n",
    "for i in range(0,len(df)):\n",
    "    len_values.append(len(df.text.iloc[i]))\n",
    "\n",
    "len_series = pd.Series(len_values)\n",
    "df['length'] = len_series.values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "      <th>length</th>\n",
       "      <th>DIGITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear caps1 caps2 believe using computer benefi...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1460</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dear caps1 caps2 caps3 people use computers ev...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>952</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear local newspaper caps1 found many expert s...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear location1 know computer positive effect p...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1466</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     y  length  DIGITS\n",
       "0  dear local newspaper think effect computer peo...   8.0    1110       5\n",
       "1  dear caps1 caps2 believe using computer benefi...   9.0    1460      10\n",
       "2  dear caps1 caps2 caps3 people use computers ev...   7.0     952       7\n",
       "3  dear local newspaper caps1 found many expert s...  10.0    2110      41\n",
       "4  dear location1 know computer positive effect p...   8.0    1466       4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the number of digits in each essay - this will serve as a geometrical parameter\n",
    "digits_list = []\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    if(sum(c.isdigit() for c in df.text.iloc[i]) == 0):\n",
    "        digits_list.append(0)\n",
    "    else:\n",
    "        digits_list.append(sum(c.isdigit() for c in df.text.iloc[i]))\n",
    "\n",
    "digits_col = pd.Series(digits_list)\n",
    "df['DIGITS'] = digits_col.values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Count the parts of speech from each of the essay\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "counts = []\n",
    "for essay in processed_essays:\n",
    "    tokenize = nltk.word_tokenize(essay)\n",
    "    tagged = nltk.pos_tag(tokenize)\n",
    "    counts.append(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the counter item to a dictionary and create a list of these dictionaries\n",
    "from collections import Counter\n",
    "pos_counter = []\n",
    "for i in counts:\n",
    "    a = Counter(tag for word,tag in i)\n",
    "    pos_counter.append(dict(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append the word count according to each type of part of speech - append 0 where there is no words belonging to a specific type\n",
    "#reference: https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/\n",
    "orderedNames = ['CC','CD','DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP'\n",
    "               , 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'WDT', 'WP', 'WP$', 'WRB']\n",
    "import numpy as np\n",
    "pos_tag_count = []\n",
    "\n",
    "for j in pos_counter:\n",
    "    b = []\n",
    "    for i in orderedNames:\n",
    "        try:\n",
    "            b.append(j[i])\n",
    "        except KeyError:\n",
    "            b.append(0)\n",
    "    pos_tag_count.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Append the counts for each essay in the dataframe df\n",
    "pos_tag_count = np.matrix(pos_tag_count)\n",
    "for i in range(len(orderedNames)):\n",
    "    df[orderedNames[i]] = pos_tag_count[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Compute a tfidf sparse matrix based on the processed_essays\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Create a sparse matrix\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(processed_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1      2      3      4      5      6      7      8      9      \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   ...    43432  43433  43434  43435  43436  43437  43438  43439  43440  43441  \n",
      "0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "1  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "2  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "3  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "4  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 43442 columns]\n"
     ]
    }
   ],
   "source": [
    "#Convert the tfidf sparse matrix to a dense matrix and append to a dataframe\n",
    "l = pd.DataFrame(X_tfidf.todense())\n",
    "print(l.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     y  length  DIGITS  \\\n",
      "0  dear local newspaper think effect computer peo...   8.0    1110       5   \n",
      "1  dear caps1 caps2 believe using computer benefi...   9.0    1460      10   \n",
      "2  dear caps1 caps2 caps3 people use computers ev...   7.0     952       7   \n",
      "3  dear local newspaper caps1 found many expert s...  10.0    2110      41   \n",
      "4  dear location1 know computer positive effect p...   8.0    1466       4   \n",
      "\n",
      "   CC  CD  DT  EX  FW  IN ...   RP  TO  UH  VB  VBD  VBG  WDT  WP  WP$  WRB  \n",
      "0   0   0   0   0   0   3 ...    0   0   0  12    4    8    0   4    0    0  \n",
      "1   0   8   3   0   0   9 ...    0   0   0  19    8   15    0   0    0    0  \n",
      "2   0   2   0   0   0   1 ...    0   0   0   6    1    7    0   0    0    0  \n",
      "3   0   0   2   1   0   3 ...    0   0   0   5   12    5    0   0    0    0  \n",
      "4   0   5   4   0   0   3 ...    1   0   0   7    0    5    0   0    0    0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from sklearn.manifold import TSNE\n",
    "#tsne = TSNE(n_components=2, verbose=1, perplexity=40)\n",
    "#feature_vectors_tsne2d = tsne.fit_transform(l)\n",
    "\n",
    "#Commenting out the above code for TSNE because of the execution time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing the dimensions of the matrix using PCA \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)  # project data down to 4 dimensions\n",
    "feature_vectors_pca2d = pca.fit_transform(X_tfidf.todense())\n",
    "l = pd.DataFrame(feature_vectors_pca2d)\n",
    "#Append the part of speech features, features from tfidf dense matrix and the geometrical features\n",
    "result = pd.concat([df, l], axis=1)\n",
    "result = result.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "      <th>length</th>\n",
       "      <th>DIGITS</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088176</td>\n",
       "      <td>-0.163062</td>\n",
       "      <td>0.019372</td>\n",
       "      <td>-0.043956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear caps1 caps2 believe using computer benefi...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076961</td>\n",
       "      <td>-0.138740</td>\n",
       "      <td>0.041166</td>\n",
       "      <td>-0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dear caps1 caps2 caps3 people use computers ev...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.084502</td>\n",
       "      <td>-0.183798</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>-0.050475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear local newspaper caps1 found many expert s...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063925</td>\n",
       "      <td>-0.138634</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>-0.033999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear location1 know computer positive effect p...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1466.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.091834</td>\n",
       "      <td>-0.143600</td>\n",
       "      <td>0.053373</td>\n",
       "      <td>-0.038958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     y  length  DIGITS  \\\n",
       "0  dear local newspaper think effect computer peo...   8.0  1110.0     5.0   \n",
       "1  dear caps1 caps2 believe using computer benefi...   9.0  1460.0    10.0   \n",
       "2  dear caps1 caps2 caps3 people use computers ev...   7.0   952.0     7.0   \n",
       "3  dear local newspaper caps1 found many expert s...  10.0  2110.0    41.0   \n",
       "4  dear location1 know computer positive effect p...   8.0  1466.0     4.0   \n",
       "\n",
       "    CC   CD   DT   EX   FW   IN    ...      VBD   VBG  WDT   WP  WP$  WRB  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  3.0    ...      4.0   8.0  0.0  4.0  0.0  0.0   \n",
       "1  0.0  8.0  3.0  0.0  0.0  9.0    ...      8.0  15.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  2.0  0.0  0.0  0.0  1.0    ...      1.0   7.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  2.0  1.0  0.0  3.0    ...     12.0   5.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  5.0  4.0  0.0  0.0  3.0    ...      0.0   5.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "          0         1         2         3  \n",
       "0 -0.088176 -0.163062  0.019372 -0.043956  \n",
       "1 -0.076961 -0.138740  0.041166 -0.013500  \n",
       "2 -0.084502 -0.183798  0.042169 -0.050475  \n",
       "3 -0.063925 -0.138634  0.011709 -0.033999  \n",
       "4 -0.091834 -0.143600  0.053373 -0.038958  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although PCA assumes linearity, I am using PCA for dimensionality reduction here just to save the execution time. Using TSNE would be better but there is a trade off for time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result.iloc[:,2:]\n",
    "y = result.iloc[:,1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### I have tried multiple models and analyzed the accuracy for them. RandomForestClassifier gives the best accuracy than 'DecisionTreeClassifier', 'OneVsRestClassifier' and 'svm'\n",
    "\n",
    "##### Hence I have decided to further fine tune the random forest classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 150], 'max_depth': [10, 27, 45, 62, 80], 'criterion': ['gini', 'entropy']}\n"
     ]
    }
   ],
   "source": [
    "#Creating a grid space with following hyperparameters\n",
    "max_depth = [int(x) for x in np.linspace(10, 80, num = 5)]\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 150, num = 3)]\n",
    "#bootstrap = [True, False]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'criterion' : criterion,\n",
    "               #'bootstrap': bootstrap\n",
    "              }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 80, 'n_estimators': 150}\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Perform grid search with the grid above to tune the Random Forest Classifier\n",
    "#reference: http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "clf = RandomForestClassifier()\n",
    "rf_random =  GridSearchCV(estimator = clf, param_grid=random_grid)\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "model = rf_random.best_estimator_\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Accuracy Score in % : \n",
      "54.08320493066255\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "print(\"RandomForestClassifier\")\n",
    "print(\"Accuracy Score in % : \")\n",
    "print(a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 4.06159243744237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rms = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE : \" + str(rms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are about 60 classes for the prediction model, the ROC curve does not provide a good indsight towards the model performance.\n",
    "\n",
    "Accuracy score which is coming out to be around 53.2%, is a good estimator of the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26062543e-01 3.94223648e-02 3.85475460e-03 1.78369122e-02\n",
      " 1.22905812e-02 2.34276736e-03 2.24958485e-03 2.48056842e-02\n",
      " 6.49354530e-02 8.53329283e-03 7.99198048e-03 0.00000000e+00\n",
      " 5.32236260e-03 8.38523623e-02 4.32955344e-02 4.88684640e-03\n",
      " 1.65243157e-06 2.06751582e-04 1.67061170e-06 1.58155435e-02\n",
      " 2.84688589e-03 4.88411755e-02 8.09246736e-03 9.40035898e-04\n",
      " 8.05944669e-03 2.68559158e-03 4.63692318e-04 2.96573269e-02\n",
      " 5.43098527e-02 3.06087159e-02 2.05306897e-03 1.59594681e-03\n",
      " 5.34773210e-05 1.52898239e-03 5.27755835e-02 1.10112019e-01\n",
      " 8.68592318e-02 9.48078565e-02]\n"
     ]
    }
   ],
   "source": [
    "feat_imp = model.feature_importances_\n",
    "#ind = np.argsort(feat_imp)[::-1]\n",
    "#feat_imp[ind]\n",
    "print(feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature among the feature space is the length feature which represents the length of the essay. There are many features which are some importance such as the use of certain words in the, digits and some specific parts of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~End of Document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
